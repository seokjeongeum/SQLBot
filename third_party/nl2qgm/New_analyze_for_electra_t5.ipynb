{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48012ee4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ANALYLZE\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import _jsonnet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools \n",
    "import transformers\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "from ratsql.commands.infer import Inferer\n",
    "from ratsql.utils.analysis import cal_attention_flow\n",
    "from search import read_data, match, show_results\n",
    "from run_all import test_example, load_model, TestInfo\n",
    "from ratsql.utils.relation_names import RELATION_NAMES, NOT_USED_RELATIONS\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859f646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for attention flow\n",
    "def draw_attention_graph(adjmat, labels_to_index, n_layers, length):\n",
    "    A = adjmat\n",
    "    G=nx.from_numpy_matrix(A, create_using=nx.DiGraph())\n",
    "    for i in np.arange(A.shape[0]):\n",
    "        for j in np.arange(A.shape[1]):\n",
    "            nx.set_edge_attributes(G, {(i,j): A[i,j]}, 'capacity')\n",
    "\n",
    "    pos = {}\n",
    "    label_pos = {}\n",
    "    for i in np.arange(n_layers+1):\n",
    "        for k_f in np.arange(length):\n",
    "            pos[i*length+k_f] = ((i+0.5)*2, length - k_f)\n",
    "            label_pos[i*length+k_f] = (i*2, length - k_f)\n",
    "\n",
    "    index_to_labels = {}\n",
    "    for key in labels_to_index:\n",
    "        index_to_labels[labels_to_index[key]] = key.split(\"_\")[-1]\n",
    "        if labels_to_index[key] >= length:\n",
    "            index_to_labels[labels_to_index[key]] = ''\n",
    "\n",
    "    #plt.figure(1,figsize=(20,12))\n",
    "\n",
    "    nx.draw_networkx_nodes(G,pos,node_color='green', node_size=50)\n",
    "    nx.draw_networkx_labels(G,pos=label_pos, labels=index_to_labels, font_size=10)\n",
    "\n",
    "    all_weights = []\n",
    "    #4 a. Iterate through the graph nodes to gather all the weights\n",
    "    for (node1,node2,data) in G.edges(data=True):\n",
    "        all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
    "\n",
    "    #4 b. Get unique weights\n",
    "    unique_weights = list(set(all_weights))\n",
    "\n",
    "    #4 c. Plot the edges - one by one!\n",
    "    for weight in unique_weights:\n",
    "        #4 d. Form a filtered list with just the weight you want to draw\n",
    "        weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in G.edges(data=True) if edge_attr['weight']==weight]\n",
    "        #4 e. I think multiplying by [num_nodes/sum(all_weights)] makes the graphs edges look cleaner\n",
    "        \n",
    "        w = weight #(weight - min(all_weights))/(max(all_weights) - min(all_weights))\n",
    "        width = w\n",
    "        nx.draw_networkx_edges(G,pos,edgelist=weighted_edges,width=width, edge_color='darkblue')\n",
    "    \n",
    "    return G\n",
    "\n",
    "def get_adjmat(mat, input_tokens):\n",
    "    n_layers, length, _ = mat.shape\n",
    "    adj_mat = np.zeros(((n_layers+1)*length, (n_layers+1)*length))\n",
    "    labels_to_index = {}\n",
    "    for k in np.arange(length):\n",
    "        labels_to_index[str(k)+\"_\"+input_tokens[k]] = k\n",
    "\n",
    "    for i in np.arange(1,n_layers+1):\n",
    "        for k_f in np.arange(length):\n",
    "            index_from = (i)*length+k_f\n",
    "            label = \"L\"+str(i)+\"_\"+str(k_f)\n",
    "            labels_to_index[label] = index_from\n",
    "            for k_t in np.arange(length):\n",
    "                index_to = (i-1)*length+k_t\n",
    "                adj_mat[index_from][index_to] = mat[i-1][k_f][k_t]\n",
    "                \n",
    "    return adj_mat, labels_to_index \n",
    "\n",
    "def add_residual_connection(attentions_mat):\n",
    "    \"\"\"\n",
    "    attentions_mat: (layer_num, head_num, seq_len, seq_len)\n",
    "    \"\"\"\n",
    "    res_att_mat = attentions_mat.sum(axis=1)/attentions_mat.shape[1]\n",
    "    res_att_mat = res_att_mat + np.eye(res_att_mat.shape[1])[None,...]\n",
    "    res_att_mat = res_att_mat / res_att_mat.sum(axis=-1)[...,None]\n",
    "    return res_att_mat\n",
    "\n",
    "def compute_flows(G, labels_to_index, input_nodes, length):\n",
    "    print(type(G))\n",
    "    print(type(labels_to_index))\n",
    "    print(type(input_nodes))\n",
    "    number_of_nodes = len(labels_to_index)\n",
    "    flow_values=np.zeros((number_of_nodes,number_of_nodes))\n",
    "    for key in labels_to_index:\n",
    "        if key not in input_nodes:\n",
    "            current_layer = int(labels_to_index[key] / length)\n",
    "            pre_layer = current_layer - 1\n",
    "            u = labels_to_index[key]\n",
    "            for inp_node_key in input_nodes:\n",
    "                v = labels_to_index[inp_node_key]\n",
    "                flow_value = nx.maximum_flow_value(G,u,v, flow_func=nx.algorithms.flow.edmonds_karp)\n",
    "                flow_values[u][pre_layer*length+v ] = flow_value\n",
    "            flow_values[u] /= flow_values[u].sum()\n",
    "            \n",
    "    return flow_values\n",
    "\n",
    "def convert_adjmat_tomats(adjmat, n_layers, l):\n",
    "    mats = np.zeros((n_layers,l,l))\n",
    "    for i in np.arange(n_layers):\n",
    "        mats[i] = adjmat[(i+1)*l:(i+2)*l,i*l:(i+1)*l]\n",
    "    return mats\n",
    "\n",
    "def plot_attention_heatmap(att, s_position, t_positions, sentence):\n",
    "      print(att[:,s_position, t_positions].shape)\n",
    "      for idx, values in enumerate(att[:,s_position, t_positions]):\n",
    "          print(f\"idx:{idx} values:{values}\")\n",
    "      cls_att = np.flip(att[:,s_position, t_positions], axis=0)\n",
    "      xticklb = input_tokens= list(itertools.compress(['<cls>']+sentence.split(), [i in t_positions for i in np.arange(len(sentence)+1)]))\n",
    "      yticklb = [str(i) if i%2 ==0 else '' for i in np.arange(att.shape[0],0, -1)]\n",
    "      ax = sns.heatmap(cls_att, xticklabels=xticklb, yticklabels=yticklb, cmap=\"YlOrRd\")\n",
    "      return ax\n",
    "\n",
    "def get_attention_flow(tokens, attentions_mat):\n",
    "    \"\"\"\n",
    "    attentions_mat: (layer_num, head_num, seq_len, seq_len)\n",
    "    \"\"\"\n",
    "    layer_num, head_num, seq_len, seq_len = attentions_mat.shape\n",
    "    res_att_mat = add_residual_connection(attentions_mat)\n",
    "    \n",
    "    # Convert matrices to adjacency matrices\n",
    "    res_adj_mat, res_labels_to_index = get_adjmat(mat=res_att_mat, input_tokens=tokens)\n",
    "\n",
    "    #@title plot the attention graph\n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    # res_adj_mat and res_labels_to_index are the results of get_adjmat()\n",
    "    res_G = draw_attention_graph(res_adj_mat,res_labels_to_index, n_layers=layer_num, length=seq_len)\n",
    "\n",
    "    # Calculate the flow values\n",
    "    input_nodes = []\n",
    "    for key in res_labels_to_index:\n",
    "        if res_labels_to_index[key] < seq_len:\n",
    "            input_nodes.append(key)\n",
    "    flow_values = compute_flows(res_G, res_labels_to_index, input_nodes, length=seq_len)\n",
    "    \n",
    "    # Convert adjacency matrix to matrices\n",
    "    flow_att_mat = convert_adjmat_tomats(flow_values, n_layers=layer_num, l=seq_len)\n",
    "\n",
    "    return flow_att_mat\n",
    "\n",
    "def draw_attention_flow(sentence, target_idx, flow_att_mat, indices_to_inspect=None):\n",
    "    # Select source indices to inspect\n",
    "    if indices_to_inspect is None:\n",
    "        indices_to_inspect = list(range(sentence))\n",
    "    \n",
    "    # Plot the attention flow\n",
    "    plt.figure(1,figsize=(3,6))\n",
    "    plot_attention_heatmap(flow_att_mat, target_idx, t_positions=indices_to_inspect, sentence=sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6348e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_dir = \"/home/hkkang/NL2QGM\"\n",
    "\n",
    "# Trained model seeds\n",
    "model_seeds = [0, 2, 3]\n",
    "\n",
    "def get_info_paths(model_type, target_model_seed):\n",
    "    bert_template = \"logdir/spider_bert_run_no_join_cond_seed_{}/bs=8,lr=7.4e-04,bert_lr=1.0e-05,end_lr=0e0,seed={},join_cond=false/ie_dirs/bert_run_true_1-step_41600-eval.json\"\n",
    "    electra_template = \"logdir/spider_electra_run_no_join_cond_seed_{}/bs=8,lr=7.4e-04,bert_lr=1.0e-05,end_lr=0e0,seed={},join_cond=false/ie_dirs/electra_run_true_1-step_41600-eval.json\"\n",
    "    glove_template = \"logdir/spider_glove_run_no_join_cond_seed_{}/bs=24,lr=7.4e-04,end_lr=0e0,seed={},join_cond=false/ie_dirs/glove_run_true_1-step_41600-eval.json\"\n",
    "    electra_t5_template = \"logdir/spider_electra_run_no_join_cond_t5_seed_3/bs=8,lr=4.4e-04,bert_lr=1.0e-05,end_lr=0e0,seed=3,join_cond=false/ie_dirs/electra_run_true_1-step_38000-eval.json\"\n",
    "    if model_type == 'bert':\n",
    "        template = bert_template\n",
    "    elif model_type == 'electra':\n",
    "        template = electra_template\n",
    "    elif model_type == 'glove':\n",
    "        template = glove_template\n",
    "    elif model_type == 't5':\n",
    "        template = electra_t5_template\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    template = os.path.join(project_dir, template)\n",
    "\n",
    "    if model_type == 'electra':\n",
    "        if target_model_seed == 0:\n",
    "            template = template.replace('41600', '18000')\n",
    "        elif target_model_seed == 2:\n",
    "            template = template.replace('41600', '25000')\n",
    "        elif target_model_seed == 3:\n",
    "            template = template.replace('41600', '26000')\n",
    "        model_seeds = [0,2,3]\n",
    "    elif model_type == 'bert':\n",
    "        if target_model_seed == 0:\n",
    "            template = template.replace('41600', '78000')\n",
    "        model_seeds = [0,2,3]\n",
    "    elif model_type == 'glove':\n",
    "        if target_model_seed == 0:\n",
    "            template = template.replace('41600', '20000')\n",
    "        elif target_model_seed == 1:\n",
    "            template = template.replace('41600', '18000')\n",
    "        elif target_model_seed == 2:\n",
    "            template = template.replace('41600', '18000')\n",
    "        model_seeds = [0,1,2]\n",
    "    elif model_type == 't5':\n",
    "        model_seeds = [3]\n",
    "        \n",
    "    eval_paths = []\n",
    "    for seed in model_seeds:\n",
    "        eval_paths += [template.format(seed, seed)]\n",
    "\n",
    "    infer_paths = [path.replace(\"-eval.json\", \"-infer.jsonl\") for path in eval_paths]\n",
    "    debug_paths = [path.replace(\"-eval.json\", \"-debug.jsonl\") for path in eval_paths]\n",
    "    return infer_paths, debug_paths, eval_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211f9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tables.json\n",
    "tables_path = os.path.join(project_dir, \"data/spider/tables.json\")\n",
    "\n",
    "with open(tables_path) as f:\n",
    "    dbs = {item['db_id']: item for item in json.load(f)}\n",
    "\n",
    "def get_column_names(db_id):\n",
    "    db = dbs[db_id]\n",
    "    tables = db['table_names']\n",
    "    columns = []\n",
    "    for table_id, column_name in db['column_names']:\n",
    "        column_name = column_name.replace(' ', '_')\n",
    "        if table_id == -1:\n",
    "            columns.append(column_name)\n",
    "        else:\n",
    "            columns.append(f\"{tables[table_id].replace(' ', '_')}.{column_name}\")\n",
    "    return columns\n",
    "\n",
    "def get_table_names(db_id):\n",
    "    db = dbs[db_id]\n",
    "    tables = db['table_names']\n",
    "    return [table.replace(' ', '_') for table in tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f68e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_json_custom(path):\n",
    "    result = json.load(open(path))['per_item']\n",
    "    return result\n",
    "\n",
    "def load_jsonl(path):\n",
    "    with open(path, 'r') as f:\n",
    "        results = [json.loads(line) for line in f.readlines()]\n",
    "    return results\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_info(eval_path, debug_path, infer_path):\n",
    "    eval_result = load_json_custom(eval_path.replace('.json', '-testing.json'))[0]\n",
    "    debug_cache = load_pickle(debug_path.replace('.jsonl', '-testing.pkl'))[0]\n",
    "    debug_result = load_jsonl(debug_path.replace('.jsonl', '-testing.jsonl'))[0]\n",
    "    infer_result = load_jsonl(infer_path.replace('.jsonl', '-testing.jsonl'))[0]\n",
    "\n",
    "    return eval_result, debug_result, debug_cache, infer_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4af37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(mma, target_labels, source_labels, title=None, decimal=4, save_as_file=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        mma: nxn weight matrix\n",
    "        source_labels: List of column labels\n",
    "        target_labels: List of row labels\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(20,20), dpi=100)\n",
    "    im = ax.imshow(mma)\n",
    "    \n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(mma.shape[1]), minor=False) # mma.shape[1] = target seq 길이\n",
    "    ax.set_yticks(np.arange(mma.shape[0]), minor=False) # mma.shape[0] = input seq 길이\n",
    "   \n",
    "    # source words -> column labels\n",
    "    ax.set_xticklabels(source_labels, minor=False)\n",
    "    # target words -> row labels\n",
    "    ax.set_yticklabels(target_labels, minor=False)\n",
    "  \n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    " \n",
    "    plt.xticks(rotation=65)\n",
    " \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(mma)):\n",
    "        for j in range(len(mma[0])):\n",
    "            if decimal == 4:\n",
    "                text = ax.text(j, i, \"{:.4f}\".format(mma[i, j].item()), ha=\"center\", va=\"center\", color=\"k\")\n",
    "            else:\n",
    "                text = ax.text(j, i, \"{:.3f}\".format(mma[i, j].item()), ha=\"center\", va=\"center\", color=\"k\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    if save_as_file:\n",
    "        plt.savefig(f'{title}.png', dpi=100)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46369ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_schema_entity_indices(eval_result, debug_result, debug_cache, infer_result):\n",
    "    db_id = eval_result['db_id']\n",
    "    questions = debug_cache['question']\n",
    "    input_columns = debug_cache['columns']\n",
    "    input_tables = debug_cache['tables']\n",
    "    columns = get_column_names(db_id)\n",
    "    tables = get_table_names(db_id)\n",
    "    assert len(columns) == len(input_columns), f\"{len(columns)} vs {len(input_columns)}\"\n",
    "    assert len(tables) == len(input_tables), f\"{len(tables)} vs {len(input_tables)}\"\n",
    "    tokens = questions + columns + tables\n",
    "    for idx, token in enumerate(tokens):\n",
    "        if idx < len(questions):\n",
    "            continue\n",
    "        if idx < (len(questions) + len(columns)):\n",
    "            entity_type = 'column'\n",
    "        else:\n",
    "            entity_type = 'table'\n",
    "        print(f\"idx:{idx}\\t{entity_type}:\\t{token}\")\n",
    "        \n",
    "def get_vector_norm(vector):\n",
    "    try:\n",
    "        return np.linalg.norm(vector)\n",
    "    except:\n",
    "        return torch.linalg.norm(vector)\n",
    "    \n",
    "def show_basic_details(eval_result, debug_result, debug_cache, infer_result):\n",
    "    db_id = eval_result['db_id']\n",
    "    nl = infer_result['question_toks']\n",
    "    pred = eval_result['predicted']\n",
    "    gold = eval_result['gold']\n",
    "    decode_history = debug_result['history']\n",
    "    correct = eval_result['exact']\n",
    "    print(f\"Is_correct:{bool(correct)}\")\n",
    "    print(f\"DB_id:{db_id}\")\n",
    "    print(f\"NL:{nl}\")\n",
    "    print(f\"Pred:{pred}\")\n",
    "    print(f\"Gold:{gold}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5228ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_encoder_details(eval_result, debug_result, debug_cache, infer_result, src_idx, des_idx, inspect_layer_num, target_key, top_k=10, prefix=None):\n",
    "    def get_layer_idx(key):\n",
    "        if 'layer' in key:\n",
    "            return int(key.split('_')[1])\n",
    "        return None\n",
    "        \n",
    "    def to_str(value):\n",
    "        if type(value) == str:\n",
    "            return value\n",
    "        elif type(value) == list:\n",
    "            return ' '.join(value)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Bad type:{value}\")\n",
    "\n",
    "    def print_top_7(joint_weight_matrix, input_tokens):\n",
    "        \"\"\"\n",
    "        joint_weight_matrix: [input_num, output_num]\n",
    "        \"\"\"\n",
    "        top_7_values, top_7_indices = torch.topk(joint_weight_matrix, k=7)\n",
    "        for cur_idx, (top_7_index, top_7_value) in enumerate(zip(top_7_indices, top_7_values)):\n",
    "            print(f\"idx:{cur_idx} word:{input_tokens[cur_idx]}\")\n",
    "            for top_idx, (item_idx, weight_value) in enumerate(zip(top_7_index, top_7_value)):\n",
    "                print(f\"\\ttop{top_idx+1}_idx:{item_idx} (word:{input_tokens[item_idx]}) {weight_value}\")\n",
    "\n",
    "    def print_top_7_for_all_layer_for_target_word(joint_weight_matrix, input_tokens, target_word_idx):\n",
    "        \"\"\"\n",
    "        joint_weight_matrix: [layer_num, input_num, output_num]\n",
    "        \"\"\"\n",
    "        joint_weight_matrix = torch.tensor(joint_weight_matrix)[:,target_word_idx,:]\n",
    "        print(joint_weight_matrix.shape)\n",
    "        top_7_values, top_7_indices = torch.topk(joint_weight_matrix, k=7)\n",
    "        for cur_idx, (top_7_index, top_7_value) in enumerate(zip(top_7_indices, top_7_values)):\n",
    "            print(f\"idx:{cur_idx} word:{input_tokens[target_word_idx]}\")\n",
    "            for top_idx, (item_idx, weight_value) in enumerate(zip(top_7_index, top_7_value)):\n",
    "                print(item_idx)\n",
    "                print(f\"\\ttop{top_idx+1}_idx:{item_idx} (word:{input_tokens[item_idx]}) {weight_value}\")\n",
    "\n",
    "                \n",
    "    def print_float(prefix, tensor):\n",
    "        assert len(tensor.shape) == 1, f\"bad: {tensor.shape}\"\n",
    "        print(prefix)\n",
    "        print(f'\\t', end='')\n",
    "        avg = sum(tensor) #/ len(tensor)\n",
    "        print(\"{:.3f}  |\\t\".format(avg), end='')\n",
    "        for value in tensor:\n",
    "            print(\"{:.3f}\\t\".format(value), end='')\n",
    "        print(\"\")\n",
    "\n",
    "    def show_attention_infos(debug_cache, tokens, inspect_layer_num, src_idx, des_idx):\n",
    "        # Show \\alpha_{ij}, e_{ij}, embedding_sim, relation_bias_sim\n",
    "        attn_probs =  debug_cache[f'layer_{inspect_layer_num}_attn_probs']\n",
    "        sim_logits =  debug_cache[f'layer_{inspect_layer_num}_sim_logits']\n",
    "        word_sim = debug_cache[f'layer_{inspect_layer_num}_emb_sim_logits']\n",
    "        bias_sim = debug_cache[f'layer_{inspect_layer_num}_bias_sim_logits']\n",
    "        relation_id = debug_cache['relation'][src_idx][des_idx]\n",
    "        relation_name = RELATION_NAMES[relation_id]\n",
    "        print(f\"layer_num:{inspect_layer_num}\")\n",
    "        print(f\"i:{src_idx} ({tokens[src_idx]}) j:{des_idx} ({tokens[des_idx]}) r:{relation_id} ({relation_name})\")\n",
    "        print_float(\"softmax_prob:\", attn_probs[:, src_idx, des_idx])\n",
    "        print_float(\"sim_score (word+bias):\", sim_logits[:, src_idx, des_idx])\n",
    "        print_float(\"word_sim:\", word_sim[:, src_idx, des_idx])\n",
    "        if len(bias_sim.shape) == 3:\n",
    "            bias_sim = bias_sim[:, src_idx, des_idx]\n",
    "        else:\n",
    "            bias_sim = torch.tensor(bias_sim).unsqueeze(0).repeat(8, 1, 1)\n",
    "        print_float(\"bias_sim:\", bias_sim[:, src_idx, des_idx])        \n",
    "        print_float(\"word_sim_prob:\", torch.softmax(torch.tensor(word_sim), dim=-1)[:, src_idx, des_idx])\n",
    "        print_float(\"bias_sim_prob:\", torch.softmax(torch.tensor(bias_sim), dim=-1)[:, src_idx, des_idx])\n",
    "        print(\"\")\n",
    "\n",
    "    def show_top_attention_infos_for_layer(target_inspect_layer_num, debug_cache, tokens, inspect_layer_num, src_idx, des_idx):\n",
    "        attn_probs = torch.tensor(debug_cache[f'layer_{target_inspect_layer_num}_attn_probs'])\n",
    "        avg_attn_probs = attn_probs.mean(dim=0)\n",
    "        if des_idx is None:\n",
    "            if top_k:\n",
    "                # Find top-10 most similary des_indices\n",
    "                top_values, top_indices = torch.topk(avg_attn_probs[src_idx], k=min(top_k, len(avg_attn_probs)))\n",
    "                des_indices = top_indices\n",
    "                # Show attention info for all target destination indices\n",
    "                for top_idx, target_des_idx in enumerate(des_indices):\n",
    "                    print(f\"Top {top_idx+1}\")\n",
    "                    show_attention_infos(debug_cache, tokens, target_inspect_layer_num, src_idx, target_des_idx)\n",
    "            else:\n",
    "                for target_des_idx in range(len(tokens)):\n",
    "                    show_attention_infos(debug_cache, tokens, target_inspect_layer_num, src_idx, target_des_idx)\n",
    "                    \n",
    "        else:\n",
    "            # Find information for des_idx\n",
    "            top_values, top_indices = torch.topk(avg_attn_probs[src_idx], k=len(avg_attn_probs))\n",
    "            # top_idx = ((top_indices == des_idx).nonzero(as_tuple=True)[0])\n",
    "            top_idx = top_indices.cpu().numpy().tolist().index(des_idx)\n",
    "            print(f\"Top {top_idx+1}\")\n",
    "            show_attention_infos(debug_cache, tokens, target_inspect_layer_num, src_idx, des_idx)\n",
    "\n",
    "    show_basic_details(eval_result, debug_result, debug_cache, infer_result)\n",
    "    db_id = eval_result['db_id']\n",
    "    pred = eval_result['predicted']\n",
    "    gold = eval_result['gold']\n",
    "    decode_history = debug_result['history']\n",
    "    correct = eval_result['exact']\n",
    "    questions = debug_cache['question']\n",
    "    input_columns = debug_cache['columns']\n",
    "    input_tables = debug_cache['tables']\n",
    "    columns = get_column_names(db_id)\n",
    "    tables = get_table_names(db_id)\n",
    "    assert len(columns) == len(input_columns), f\"{len(columns)} vs {len(input_columns)}\"\n",
    "    assert len(tables) == len(input_tables), f\"{len(tables)} vs {len(input_tables)}\"\n",
    "    tokens = questions + columns + tables\n",
    "    tokens_len = len(tokens)\n",
    "    # Attention flow\n",
    "    if target_key == \"attention_score\":\n",
    "        # Select target destination indices\n",
    "        if inspect_layer_num is None:\n",
    "            for target_inspect_layer_num in range(8):\n",
    "                show_top_attention_infos_for_layer(target_inspect_layer_num,\n",
    "                                                   debug_cache, tokens, target_inspect_layer_num, src_idx, des_idx)\n",
    "        else:\n",
    "            target_inspect_layer_num = inspect_layer_num\n",
    "            show_top_attention_infos_for_layer(target_inspect_layer_num,\n",
    "                                    debug_cache, tokens, target_inspect_layer_num, src_idx, des_idx)\n",
    "\n",
    "    elif target_key == 'draw_attention_prob':\n",
    "        # Draw input x input matrix\n",
    "        for target_inspect_layer_num in range(8):\n",
    "            attn_probs = torch.tensor(debug_cache[f'layer_{target_inspect_layer_num}_attn_probs'])\n",
    "            avg_attn_probs = attn_probs.sum(dim=0)\n",
    "            x = tokens\n",
    "            y = tokens\n",
    "            visualize_attention(avg_attn_probs, x, y, title=f'{prefix}_token-token_attention_prob_layer-{target_inspect_layer_num}', decimal=3, save_as_file=True)\n",
    "            \n",
    "    elif target_key == 'draw_word_embeddings':\n",
    "        # Draw input x input matrix\n",
    "        for target_inspect_layer_num in range(8):\n",
    "            word_sim = debug_cache[f'layer_{target_inspect_layer_num}_emb_sim_logits']\n",
    "            word_sim_prob = torch.softmax(torch.tensor(word_sim), dim=-1).squeeze(0)\n",
    "            avg_word_sim_prob = word_sim_prob.sum(dim=0)\n",
    "            x = tokens\n",
    "            y = tokens\n",
    "            visualize_attention(avg_word_sim_prob, x, y, title=f'{prefix}_token-token_word_prob_layer-{target_inspect_layer_num}', decimal=3, save_as_file=True)    \n",
    "    \n",
    "    elif target_key == 'draw_relation_embeddings':\n",
    "        avg_bias_sim_probs = []\n",
    "        for target_inspect_layer_num in range(8):\n",
    "            ## 1. Draw input x input\n",
    "            ### 1.1 Create attention matrix: input x input\n",
    "            bias_sim = debug_cache[f'layer_{target_inspect_layer_num}_bias_sim_logits']\n",
    "            bias_sim_prob = torch.softmax(torch.tensor(bias_sim), dim=-1).squeeze(0)\n",
    "            avg_bias_sim_prob = bias_sim_prob.sum(dim=0)\n",
    "            avg_bias_sim_probs.append(avg_bias_sim_prob)\n",
    "        \n",
    "            ## 2. Draw input x relation\n",
    "            ### 2.1 Create attention matrix: input x relation\n",
    "            attention_matrix = torch.zeros(avg_bias_sim_prob.shape[0], len(RELATION_NAMES))\n",
    "            history = []\n",
    "            for src_idx in range(avg_bias_sim_prob.shape[0]):\n",
    "                for target_des_idx in range(bias_sim_prob.shape[-1]):\n",
    "                    relation_id = debug_cache['relation'][src_idx][target_des_idx]\n",
    "                    relation_name = RELATION_NAMES[relation_id]\n",
    "                    if relation_id not in history:\n",
    "                        history.append(relation_id)\n",
    "                    attention_matrix[src_idx][relation_id] = avg_bias_sim_prob[src_idx][target_des_idx]\n",
    "            \n",
    "            # Filter out unused relations\n",
    "            history = sorted(list(set(history)))\n",
    "            filtered_relation_names = [RELATION_NAMES[i] for i in history]\n",
    "            filtered_attention_matrix = torch.zeros(avg_bias_sim_prob.shape[0], len(history))\n",
    "            for source_idx in range(avg_bias_sim_prob.shape[0]):\n",
    "                for relation_id in debug_cache['relation'][source_idx]:\n",
    "                    idx = history.index(relation_id)\n",
    "                    filtered_attention_matrix[source_idx, idx] = attention_matrix[source_idx, relation_id]\n",
    "            \n",
    "            ### 2.2 Draw attention matrix\n",
    "            x = tokens\n",
    "            y = filtered_relation_names\n",
    "            visualize_attention(filtered_attention_matrix, x, y, title=f'{prefix}_token-relation_bias_prob_layer-{target_inspect_layer_num}', decimal=3, save_as_file=True)\n",
    "        \n",
    "        # Draw attention matrix\n",
    "        for layer_num, avg_bias_sim_prob in enumerate(avg_bias_sim_probs):\n",
    "            x = tokens\n",
    "            y = tokens\n",
    "            visualize_attention(avg_bias_sim_prob, x, y, title=f'{prefix}_token-token_bias_prob_layer-{layer_num}', decimal=3, save_as_file=True)\n",
    "    elif target_key == 'relation_embeddings':\n",
    "        # Get all relation ids used in src_idx\n",
    "        relation_ids = list(set(debug_cache['relation'][src_idx]))\n",
    "        \n",
    "        for inspect_layer_num in range(8):\n",
    "            attn_probs =  debug_cache[f'layer_{inspect_layer_num}_attn_probs']\n",
    "            sim_logits =  debug_cache[f'layer_{inspect_layer_num}_sim_logits']\n",
    "            word_sim = debug_cache[f'layer_{inspect_layer_num}_emb_sim_logits']\n",
    "            bias_sim = debug_cache[f'layer_{inspect_layer_num}_bias_sim_logits']\n",
    "            print(f\"layer_num:{inspect_layer_num}\")\n",
    "            bias_sim_prob = torch.softmax(torch.tensor(bias_sim), dim=-1).squeeze(0)[:, src_idx].data.cpu().numpy()\n",
    "\n",
    "            history = []\n",
    "            for target_des_idx in range(bias_sim_prob.shape[-1]):\n",
    "                relation_id = debug_cache['relation'][src_idx][target_des_idx]\n",
    "                relation_name = RELATION_NAMES[relation_id]\n",
    "                cnt_relation_id = np.count_nonzero(debug_cache['relation'][src_idx] == relation_id)\n",
    "                if relation_id not in history:\n",
    "                    history.append(relation_id)\n",
    "                    avg_prob = sum(bias_sim_prob[:, target_des_idx]) / bias_sim_prob.shape[0]\n",
    "                    print(f\"\\trelation_id: {relation_id} ({relation_name}) x {cnt_relation_id}\")\n",
    "                    print('\\t\\t\\t\\t{:.3f} |\\t'.format(avg_prob), end='')\n",
    "                    \n",
    "                    for value in bias_sim_prob[:, target_des_idx]:\n",
    "                        print(\"{:.3f}\\t\".format(value), end='')\n",
    "                    print('')\n",
    "\n",
    "    elif target_key  == 'relation_embeddings':\n",
    "        assert inspect_layer_num is not None, \"Inspect_layer_num should not be None\"\n",
    "        for key, value in debug_cache.items():\n",
    "            if inspect_layer_num == get_layer_idx(key):\n",
    "                if 'relation_k_embs' in key or 'relation_v_embs' in key:\n",
    "                    print(key)\n",
    "                    for relation_id, relation_emb in enumerate(value):\n",
    "                        print(f\"Relation: {relation_id} ({RELATION_NAMES[relation_id]}) scale: {get_vector_norm(relation_emb)}\")\n",
    "                    print('')\n",
    "\n",
    "    elif target_key in ['attention_flow']:\n",
    "        bert_attention = torch.stack(debug_cache['bert_attention']).squeeze(1)\n",
    "        bert_attention = bert_attention[:3]\n",
    "        bert_tokens = debug_cache['input_tokens']\n",
    "        flow_att_mat = get_attention_flow(bert_tokens, bert_attention)\n",
    "        sentence = ' '.join(bert_tokens[1:-1])\n",
    "        draw_attention_flow(sentence, 3, flow_att_mat, [10, 14])\n",
    "\n",
    "    elif target_key in ['semi_attention_flow']:\n",
    "        bert_attention = torch.stack(debug_cache['bert_attention']).squeeze(1)\n",
    "        bert_tokens = debug_cache['input_tokens']\n",
    "        joint_weight_matrix = cal_attention_flow(bert_attention)\n",
    "        ## Create label\n",
    "        # target_labels = list(map(to_str, bert_input))\n",
    "        # source_labels = target_labels\n",
    "        # visualize_attention(joint_weight_matrix, source_labels, target_labels, title='Bert attention flow')\n",
    "        \n",
    "        # Show top 10 words instead of visualization\n",
    "        # Top 7 index and value from weights tensor\n",
    "        # print_top_7(joint_weight_matrix, bert_input)\n",
    "        print_top_7_for_all_layer_for_target_word(bert_attention.sum(dim=1)/bert_attention.shape[1], bert_tokens, 3)\n",
    "\n",
    "    # More detail attention\n",
    "    else:\n",
    "        for key, value in debug_cache.items():\n",
    "            layer_idx = get_layer_idx(key)\n",
    "\n",
    "            # only show desired key\n",
    "            if \"_\".join(key.split('_')[2:]) != target_key:\n",
    "                continue\n",
    "\n",
    "            tmps = []\n",
    "            for tmp_des_idx in range(tokens_len):\n",
    "                if 'sim_logits' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'attn_probs' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'emb_sim_logits' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'bias_sim_logits' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'relation_k_embs' in key:\n",
    "                    relation_idx = debug_cache[f'layer_{layer_idx}_relation'][src_idx][tmp_des_idx]\n",
    "                    target_value = get_vector_norm(value[relation_idx])\n",
    "                elif 'relation_v_embs' in key:\n",
    "                    relation_idx = debug_cache[f'layer_{layer_idx}_relation'][src_idx][tmp_des_idx]\n",
    "                    target_value = get_vector_norm(value[relation_idx])\n",
    "\n",
    "                print(f\"key:{key} src:{src_idx} ({tokens[src_idx]}) -> des:{tmp_des_idx} ({tokens[tmp_des_idx]}) value:{target_value}\")\n",
    "                tmps.append(np.expand_dims(target_value, axis=0))\n",
    "\n",
    "            # Draw attention\n",
    "            target_labels = list(map(to_str, [tokens[src_idx]]))\n",
    "            source_labels = list(map(to_str, tokens))\n",
    "            tmps = np.stack(tmps)\n",
    "            visualize_attention(np.stack(tmps), source_labels, target_labels, title=key)\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    #\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ae8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_encoder_details(eval_result, debug_result, debug_cache, infer_result, src_idx, des_idx, inspect_layer_num, target_key, top_k=10, prefix=None):\n",
    "    def get_layer_idx(key):\n",
    "        if 'layer' in key:\n",
    "            return int(key.split('_')[1])\n",
    "        return None\n",
    "        \n",
    "    def to_str(value):\n",
    "        if type(value) == str:\n",
    "            return value\n",
    "        elif type(value) == list:\n",
    "            return ' '.join(value)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Bad type:{value}\")\n",
    "\n",
    "    def print_top_7(joint_weight_matrix, input_tokens):\n",
    "        \"\"\"\n",
    "        joint_weight_matrix: [input_num, output_num]\n",
    "        \"\"\"\n",
    "        top_7_values, top_7_indices = torch.topk(joint_weight_matrix, k=7)\n",
    "        for cur_idx, (top_7_index, top_7_value) in enumerate(zip(top_7_indices, top_7_values)):\n",
    "            print(f\"idx:{cur_idx} word:{input_tokens[cur_idx]}\")\n",
    "            for top_idx, (item_idx, weight_value) in enumerate(zip(top_7_index, top_7_value)):\n",
    "                print(f\"\\ttop{top_idx+1}_idx:{item_idx} (word:{input_tokens[item_idx]}) {weight_value}\")\n",
    "\n",
    "    def print_top_7_for_all_layer_for_target_word(joint_weight_matrix, input_tokens, target_word_idx):\n",
    "        \"\"\"\n",
    "        joint_weight_matrix: [layer_num, input_num, output_num]\n",
    "        \"\"\"\n",
    "        joint_weight_matrix = torch.tensor(joint_weight_matrix)[:,target_word_idx,:]\n",
    "        print(joint_weight_matrix.shape)\n",
    "        top_7_values, top_7_indices = torch.topk(joint_weight_matrix, k=7)\n",
    "        for cur_idx, (top_7_index, top_7_value) in enumerate(zip(top_7_indices, top_7_values)):\n",
    "            print(f\"idx:{cur_idx} word:{input_tokens[target_word_idx]}\")\n",
    "            for top_idx, (item_idx, weight_value) in enumerate(zip(top_7_index, top_7_value)):\n",
    "                print(item_idx)\n",
    "                print(f\"\\ttop{top_idx+1}_idx:{item_idx} (word:{input_tokens[item_idx]}) {weight_value}\")\n",
    "\n",
    "                \n",
    "    def print_float(prefix, tensor):\n",
    "        assert len(tensor.shape) == 1, f\"bad: {tensor.shape}\"\n",
    "        print(prefix)\n",
    "        print(f'\\t', end='')\n",
    "        avg = sum(tensor) #/ len(tensor)\n",
    "        print(\"{:.3f}  |\\t\".format(avg), end='')\n",
    "        for value in tensor:\n",
    "            print(\"{:.3f}\\t\".format(value), end='')\n",
    "        print(\"\")\n",
    "\n",
    "    def show_attention_infos(debug_cache, tokens, inspect_layer_num, src_idx, des_idx):\n",
    "        # Show \\alpha_{ij}, e_{ij}, embedding_sim, relation_bias_sim\n",
    "        attn_probs =  debug_cache[f'layer_{inspect_layer_num}_attn_probs']\n",
    "        sim_logits =  debug_cache[f'layer_{inspect_layer_num}_sim_logits']\n",
    "        word_sim = debug_cache[f'layer_{inspect_layer_num}_emb_sim_logits']\n",
    "        bias_sim = debug_cache[f'layer_{inspect_layer_num}_bias_sim_logits']\n",
    "        relation_id = debug_cache['relation'][src_idx][des_idx]\n",
    "        relation_name = RELATION_NAMES[relation_id]\n",
    "        print(f\"layer_num:{inspect_layer_num}\")\n",
    "        print(f\"i:{src_idx} ({tokens[src_idx]}) j:{des_idx} ({tokens[des_idx]}) r:{relation_id} ({relation_name})\")\n",
    "        print_float(\"softmax_prob:\", attn_probs[:, src_idx, des_idx])\n",
    "        print_float(\"sim_score (word+bias):\", sim_logits[:, src_idx, des_idx])\n",
    "        print_float(\"word_sim:\", word_sim[:, src_idx, des_idx])\n",
    "        if len(bias_sim.shape) == 3:\n",
    "            bias_sim = bias_sim[:, src_idx, des_idx]\n",
    "        else:\n",
    "            bias_sim = torch.tensor(bias_sim).unsqueeze(0).repeat(8, 1, 1)\n",
    "        print_float(\"bias_sim:\", bias_sim[:, src_idx, des_idx])        \n",
    "        print_float(\"word_sim_prob:\", torch.softmax(torch.tensor(word_sim), dim=-1)[:, src_idx, des_idx])\n",
    "        print_float(\"bias_sim_prob:\", torch.softmax(torch.tensor(bias_sim), dim=-1)[:, src_idx, des_idx])\n",
    "        print(\"\")\n",
    "\n",
    "    def show_top_attention_infos_for_layer(target_inspect_layer_num, debug_cache, tokens, inspect_layer_num, src_idx, des_idx):\n",
    "        attn_probs = torch.tensor(debug_cache[f'layer_{target_inspect_layer_num}_attn_probs'])\n",
    "        avg_attn_probs = attn_probs.mean(dim=0)\n",
    "        if des_idx is None:\n",
    "            if top_k:\n",
    "                # Find top-10 most similary des_indices\n",
    "                top_values, top_indices = torch.topk(avg_attn_probs[src_idx], k=min(top_k, len(avg_attn_probs)))\n",
    "                des_indices = top_indices\n",
    "                # Show attention info for all target destination indices\n",
    "                for top_idx, target_des_idx in enumerate(des_indices):\n",
    "                    print(f\"Top {top_idx+1}\")\n",
    "                    show_attention_infos(debug_cache, tokens, target_inspect_layer_num, src_idx, target_des_idx)\n",
    "            else:\n",
    "                for target_des_idx in range(len(tokens)):\n",
    "                    show_attention_infos(debug_cache, tokens, target_inspect_layer_num, src_idx, target_des_idx)\n",
    "                    \n",
    "        else:\n",
    "            # Find information for des_idx\n",
    "            top_values, top_indices = torch.topk(avg_attn_probs[src_idx], k=len(avg_attn_probs))\n",
    "            # top_idx = ((top_indices == des_idx).nonzero(as_tuple=True)[0])\n",
    "            top_idx = top_indices.cpu().numpy().tolist().index(des_idx)\n",
    "            print(f\"Top {top_idx+1}\")\n",
    "            show_attention_infos(debug_cache, tokens, target_inspect_layer_num, src_idx, des_idx)\n",
    "\n",
    "    show_basic_details(eval_result, debug_result, debug_cache, infer_result)\n",
    "    db_id = eval_result['db_id']\n",
    "    pred = eval_result['predicted']\n",
    "    gold = eval_result['gold']\n",
    "    decode_history = debug_result['history']\n",
    "    correct = eval_result['exact']\n",
    "    questions = debug_cache['question']\n",
    "    input_columns = debug_cache['columns']\n",
    "    input_tables = debug_cache['tables']\n",
    "    columns = get_column_names(db_id)\n",
    "    tables = get_table_names(db_id)\n",
    "    assert len(columns) == len(input_columns), f\"{len(columns)} vs {len(input_columns)}\"\n",
    "    assert len(tables) == len(input_tables), f\"{len(tables)} vs {len(input_tables)}\"\n",
    "    tokens = questions + columns + tables\n",
    "    tokens_len = len(tokens)\n",
    "    # Attention flow\n",
    "    if target_key == \"attention_score\":\n",
    "        # Select target destination indices\n",
    "        if inspect_layer_num is None:\n",
    "            for target_inspect_layer_num in range(8):\n",
    "                show_top_attention_infos_for_layer(target_inspect_layer_num,\n",
    "                                                   debug_cache, tokens, target_inspect_layer_num, src_idx, des_idx)\n",
    "        else:\n",
    "            target_inspect_layer_num = inspect_layer_num\n",
    "            show_top_attention_infos_for_layer(target_inspect_layer_num,\n",
    "                                    debug_cache, tokens, target_inspect_layer_num, src_idx, des_idx)\n",
    "\n",
    "    elif target_key == 'draw_attention_prob':\n",
    "        # Draw input x input matrix\n",
    "        for target_inspect_layer_num in range(8):\n",
    "            attn_probs = torch.tensor(debug_cache[f'layer_{target_inspect_layer_num}_attn_probs'])\n",
    "            avg_attn_probs = attn_probs.sum(dim=0)\n",
    "            x = tokens\n",
    "            y = tokens\n",
    "            visualize_attention(avg_attn_probs, x, y, title=f'{prefix}_token-token_attention_prob_layer-{target_inspect_layer_num}', decimal=3, save_as_file=True)\n",
    "            \n",
    "    elif target_key == 'draw_word_embeddings':\n",
    "        # Draw input x input matrix\n",
    "        for target_inspect_layer_num in range(8):\n",
    "            word_sim = debug_cache[f'layer_{target_inspect_layer_num}_emb_sim_logits']\n",
    "            word_sim_prob = torch.softmax(torch.tensor(word_sim), dim=-1).squeeze(0)\n",
    "            avg_word_sim_prob = word_sim_prob.sum(dim=0)\n",
    "            x = tokens\n",
    "            y = tokens\n",
    "            visualize_attention(avg_word_sim_prob, x, y, title=f'{prefix}_token-token_word_prob_layer-{target_inspect_layer_num}', decimal=3, save_as_file=True)    \n",
    "    \n",
    "    elif target_key == 'draw_relation_embeddings':\n",
    "        avg_bias_sim_probs = []\n",
    "        for target_inspect_layer_num in range(8):\n",
    "            ## 1. Draw input x input\n",
    "            ### 1.1 Create attention matrix: input x input\n",
    "            bias_sim = debug_cache[f'layer_{target_inspect_layer_num}_bias_sim_logits']\n",
    "            bias_sim_prob = torch.softmax(torch.tensor(bias_sim), dim=-1).squeeze(0)\n",
    "            avg_bias_sim_prob = bias_sim_prob.sum(dim=0)\n",
    "            avg_bias_sim_probs.append(avg_bias_sim_prob)\n",
    "        \n",
    "            ## 2. Draw input x relation\n",
    "            ### 2.1 Create attention matrix: input x relation\n",
    "            attention_matrix = torch.zeros(avg_bias_sim_prob.shape[0], len(RELATION_NAMES))\n",
    "            history = []\n",
    "            for src_idx in range(avg_bias_sim_prob.shape[0]):\n",
    "                for target_des_idx in range(bias_sim_prob.shape[-1]):\n",
    "                    relation_id = debug_cache['relation'][src_idx][target_des_idx]\n",
    "                    relation_name = RELATION_NAMES[relation_id]\n",
    "                    if relation_id not in history:\n",
    "                        history.append(relation_id)\n",
    "                    attention_matrix[src_idx][relation_id] = avg_bias_sim_prob[src_idx][target_des_idx]\n",
    "            \n",
    "            # Filter out unused relations\n",
    "            history = sorted(list(set(history)))\n",
    "            filtered_relation_names = [RELATION_NAMES[i] for i in history]\n",
    "            filtered_attention_matrix = torch.zeros(avg_bias_sim_prob.shape[0], len(history))\n",
    "            for source_idx in range(avg_bias_sim_prob.shape[0]):\n",
    "                for relation_id in debug_cache['relation'][source_idx]:\n",
    "                    idx = history.index(relation_id)\n",
    "                    filtered_attention_matrix[source_idx, idx] = attention_matrix[source_idx, relation_id]\n",
    "            \n",
    "            ### 2.2 Draw attention matrix\n",
    "            x = tokens\n",
    "            y = filtered_relation_names\n",
    "            visualize_attention(filtered_attention_matrix, x, y, title=f'{prefix}_token-relation_bias_prob_layer-{target_inspect_layer_num}', decimal=3, save_as_file=True)\n",
    "        \n",
    "        # Draw attention matrix\n",
    "        for layer_num, avg_bias_sim_prob in enumerate(avg_bias_sim_probs):\n",
    "            x = tokens\n",
    "            y = tokens\n",
    "            visualize_attention(avg_bias_sim_prob, x, y, title=f'{prefix}_token-token_bias_prob_layer-{layer_num}', decimal=3, save_as_file=True)\n",
    "        \n",
    "\n",
    "    elif target_key == 'print_relation_embeddings':\n",
    "        for inspect_layer_num in range(8):\n",
    "            print(f\"\\nlayer_num:{inspect_layer_num+1}\")\n",
    "            relational_bias = debug_cache[f'layer_{inspect_layer_num}_relation_k_embs']\n",
    "            assert len(relational_bias) == len(RELATION_NAMES)\n",
    "            for relation_idx in range(len(relational_bias)):\n",
    "                relation_name = RELATION_NAMES[relation_idx]\n",
    "                if relation_name in NOT_USED_RELATIONS:\n",
    "                    continue\n",
    "                print(f\"id: {relation_idx} relation: {relation_name} bias: {relational_bias[relation_idx][0]}\")\n",
    "            \n",
    "            \n",
    "    elif target_key == 'relation_embeddings':\n",
    "        # Get all relation ids used in src_idx\n",
    "        relation_ids = list(set(debug_cache['relation'][src_idx]))\n",
    "        \n",
    "        for inspect_layer_num in range(8):\n",
    "            attn_probs =  debug_cache[f'layer_{inspect_layer_num}_attn_probs']\n",
    "            sim_logits =  debug_cache[f'layer_{inspect_layer_num}_sim_logits']\n",
    "            word_sim = debug_cache[f'layer_{inspect_layer_num}_emb_sim_logits']\n",
    "            bias_sim = debug_cache[f'layer_{inspect_layer_num}_bias_sim_logits']\n",
    "            print(f\"layer_num:{inspect_layer_num}\")\n",
    "            bias_sim_prob = torch.softmax(torch.tensor(bias_sim), dim=-1).squeeze(0)[:, src_idx].data.cpu().numpy()\n",
    "\n",
    "            history = []\n",
    "            for target_des_idx in range(bias_sim_prob.shape[-1]):\n",
    "                relation_id = debug_cache['relation'][src_idx][target_des_idx]\n",
    "                relation_name = RELATION_NAMES[relation_id]\n",
    "                cnt_relation_id = np.count_nonzero(debug_cache['relation'][src_idx] == relation_id)\n",
    "                if relation_id not in history:\n",
    "                    history.append(relation_id)\n",
    "                    avg_prob = sum(bias_sim_prob[:, target_des_idx]) / bias_sim_prob.shape[0]\n",
    "                    print(f\"\\trelation_id: {relation_id} ({relation_name}) x {cnt_relation_id}\")\n",
    "                    print('\\t\\t\\t\\t{:.3f} |\\t'.format(avg_prob), end='')\n",
    "                    \n",
    "                    for value in bias_sim_prob[:, target_des_idx]:\n",
    "                        print(\"{:.3f}\\t\".format(value), end='')\n",
    "                    print('')\n",
    "\n",
    "    elif target_key  == 'relation_embeddings':\n",
    "        assert inspect_layer_num is not None, \"Inspect_layer_num should not be None\"\n",
    "        for key, value in debug_cache.items():\n",
    "            if inspect_layer_num == get_layer_idx(key):\n",
    "                if 'relation_k_embs' in key or 'relation_v_embs' in key:\n",
    "                    print(key)\n",
    "                    for relation_id, relation_emb in enumerate(value):\n",
    "                        print(f\"Relation: {relation_id} ({RELATION_NAMES[relation_id]}) scale: {get_vector_norm(relation_emb)}\")\n",
    "                    print('')\n",
    "\n",
    "    elif target_key in ['attention_flow']:\n",
    "        bert_attention = torch.stack(debug_cache['bert_attention']).squeeze(1)\n",
    "        bert_attention = bert_attention[:3]\n",
    "        bert_tokens = debug_cache['input_tokens']\n",
    "        flow_att_mat = get_attention_flow(bert_tokens, bert_attention)\n",
    "        sentence = ' '.join(bert_tokens[1:-1])\n",
    "        draw_attention_flow(sentence, 3, flow_att_mat, [10, 14])\n",
    "\n",
    "    elif target_key in ['semi_attention_flow']:\n",
    "        bert_attention = torch.stack(debug_cache['bert_attention']).squeeze(1)\n",
    "        bert_tokens = debug_cache['input_tokens']\n",
    "        joint_weight_matrix = cal_attention_flow(bert_attention)\n",
    "        ## Create label\n",
    "        # target_labels = list(map(to_str, bert_input))\n",
    "        # source_labels = target_labels\n",
    "        # visualize_attention(joint_weight_matrix, source_labels, target_labels, title='Bert attention flow')\n",
    "        \n",
    "        # Show top 10 words instead of visualization\n",
    "        # Top 7 index and value from weights tensor\n",
    "        # print_top_7(joint_weight_matrix, bert_input)\n",
    "        print_top_7_for_all_layer_for_target_word(bert_attention.sum(dim=1)/bert_attention.shape[1], bert_tokens, 3)\n",
    "\n",
    "    # More detail attention\n",
    "    else:\n",
    "        for key, value in debug_cache.items():\n",
    "            layer_idx = get_layer_idx(key)\n",
    "\n",
    "            # only show desired key\n",
    "            if \"_\".join(key.split('_')[2:]) != target_key:\n",
    "                continue\n",
    "\n",
    "            tmps = []\n",
    "            for tmp_des_idx in range(tokens_len):\n",
    "                if 'sim_logits' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'attn_probs' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'emb_sim_logits' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'bias_sim_logits' in key:\n",
    "                    target_value = value[src_idx][tmp_des_idx]\n",
    "                elif 'relation_k_embs' in key:\n",
    "                    relation_idx = debug_cache[f'layer_{layer_idx}_relation'][src_idx][tmp_des_idx]\n",
    "                    target_value = get_vector_norm(value[relation_idx])\n",
    "                elif 'relation_v_embs' in key:\n",
    "                    relation_idx = debug_cache[f'layer_{layer_idx}_relation'][src_idx][tmp_des_idx]\n",
    "                    target_value = get_vector_norm(value[relation_idx])\n",
    "\n",
    "                print(f\"key:{key} src:{src_idx} ({tokens[src_idx]}) -> des:{tmp_des_idx} ({tokens[tmp_des_idx]}) value:{target_value}\")\n",
    "                tmps.append(np.expand_dims(target_value, axis=0))\n",
    "\n",
    "            # Draw attention\n",
    "            target_labels = list(map(to_str, [tokens[src_idx]]))\n",
    "            source_labels = list(map(to_str, tokens))\n",
    "            tmps = np.stack(tmps)\n",
    "            visualize_attention(np.stack(tmps), source_labels, target_labels, title=key)\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    #\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f524e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "def show_decoder_details(eval_result, debug_result, debug_cache, infer_result, inspect_step_idx=None):\n",
    "    show_basic_details(eval_result, debug_result, debug_cache, infer_result)\n",
    "    db_id = eval_result['db_id']\n",
    "    decode_history = debug_result['history']\n",
    "    input_columns = debug_cache['columns']\n",
    "    input_tables = debug_cache['tables']\n",
    "    columns = get_column_names(db_id)\n",
    "    tables = get_table_names(db_id)\n",
    "    assert len(columns) == len(input_columns), f\"{len(columns)} vs {len(input_columns)}\"\n",
    "    assert len(tables) == len(input_tables), f\"{len(tables)} vs {len(input_tables)}\"\n",
    "    \n",
    "    if inspect_step_idx is None:\n",
    "        # Show all steps briefly\n",
    "        for step, step_info in enumerate(decode_history):\n",
    "            print(f\"Step: {step}\")\n",
    "            rule_left = step_info['rule_left']\n",
    "            choices = step_info['choices']\n",
    "            probs = step_info['probs']\n",
    "\n",
    "            # Decoder: action choices and probs\n",
    "            print(f\"rule_left: {rule_left}\")\n",
    "            print(f\"choices: {choices}\")\n",
    "            print(f\"probs: {['{:.2f}'.format(prob*100) for prob in probs]}\\n\")\n",
    "        return None\n",
    "    else:\n",
    "        # Analyze decoding steps\n",
    "        for step, step_info in enumerate(decode_history):\n",
    "            if inspect_step_idx != None and inspect_step_idx != step:\n",
    "                continue\n",
    "\n",
    "            # For easy referencing\n",
    "            db_id = infer_result['db_id']\n",
    "            nl_toks = infer_result['question_toks']\n",
    "            ## Schema and memory\n",
    "            tables = [' '.join(item) for item in infer_result['schema']['tables']]\n",
    "            columns_no_table = [' '.join(item[:-1]) for item in infer_result['schema']['columns']]\n",
    "            memory = nl_toks+columns+tables\n",
    "            ## align_mat\n",
    "            mc_align_matrix = torch.tensor(debug_cache['m2c_align_mat'])\n",
    "            mt_align_matrix = torch.tensor(debug_cache['m2t_align_mat'])\n",
    "            ## action scores\n",
    "            decode_history = debug_result['history']\n",
    "            ## encoder attention weight for each layers\n",
    "\n",
    "            print(f\"Step: {step}\")\n",
    "            # For easy reference\n",
    "            rule_left = step_info['rule_left']\n",
    "            choices = step_info['choices']\n",
    "            probs = step_info['probs']\n",
    "\n",
    "            # Decoder: action choices and probs\n",
    "            print(f\"rule_left: {rule_left}\")\n",
    "            print(f\"choices: {choices}\")\n",
    "            print(f\"probs: {['{:.2f}'.format(prob*100) for prob in probs]}\")\n",
    "\n",
    "            # Decoder: hidden state - memory attention\n",
    "            dec_att = torch.tensor(step_info['att_probs'])\n",
    "            visualize_attention(dec_att.transpose(0,1), memory, ['hidden_state'],\n",
    "                                    title=\"Hidden state - Memory attention\")\n",
    "\n",
    "            # More info for column/table\n",
    "            if rule_left in ['column', 'table']:\n",
    "                    # Analyze align matrix\n",
    "                if rule_left == 'column':\n",
    "                    visualize_attention(mc_align_matrix, memory, columns_no_table, title=\"Memory - Column alignment\", decimal=3)\n",
    "                else:\n",
    "                    visualize_attention(mt_align_matrix, memory, tables, title=\"Memory - Table alignment\", decimal=3)\n",
    "                \n",
    "                # Decoder: memory-pointer probs\n",
    "                memory_pointer_probs = torch.tensor(step_info['memory_pointer_probs'])\n",
    "                visualize_attention(memory_pointer_probs.transpose(0, 1), \n",
    "                                    memory, ['hidden_state'], title='Memory pointer probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e081fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING <class 'ratsql.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n",
      "WARNING <class 'ratsql.models.enc_dec.EncDecModel'>: superfluous {'decoder_preproc': {'grammar': {'clause_order': None, 'end_with_from': True, 'factorize_sketch': 2, 'include_literals': False, 'infer_from_conditions': False, 'name': 'spider', 'output_from': True, 'use_table_pointer': True}, 'save_path': 'data/spider_test/nl2code,join_cond=false,output_from=true,fs=2,emb=electrasquad,cvlink', 'use_seq_elem_rules': True}, 'encoder_preproc': {'bert_version': 'ahotrod/electra_large_discriminator_squad2_512', 'compute_cv_link': True, 'compute_sc_link': True, 'db_path': 'data/spider_test/database', 'fix_issue_16_primary_keys': True, 'include_table_name_in_column': False, 'save_path': 'data/spider_test/nl2code,join_cond=false,output_from=true,fs=2,emb=electrasquad,cvlink'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from logdir/spider_electra_run_no_join_cond_t5_seed_3/bs=8,lr=4.4e-04,bert_lr=1.0e-05,end_lr=0e0,seed=3,join_cond=false/model_checkpoint-038000.pt\n",
      "loaded model has last_step:38000\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "warnings.filterwarnings('ignore')\n",
    "# trained_bert_models = [load_model(seed, model_type='bert') for seed in model_seeds]\n",
    "# trained_electra_models = [load_model(seed, model_type='electra') for seed in model_seeds]\n",
    "# trained_glove_models = [load_model(seed, model_type='glove') for seed in [0,1,2]]\n",
    "trained_t5_models = [load_model(seed, model_type='t5') for seed in [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING <class 'ratsql.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n",
      "DB connections: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 166/166 [00:00<00:00, 311.26it/s]\n",
      "test section:   0%|                                                                                                                          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test section: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "WARNING <class 'ratsql.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n",
      "DB connections: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 166/166 [00:00<00:00, 470.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before summary writer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DB connections: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 166/166 [00:00<00:00, 360.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote eval results to logdir/spider_electra_run_no_join_cond_t5_seed_3/bs=8,lr=4.4e-04,bert_lr=1.0e-05,end_lr=0e0,seed=3,join_cond=false/ie_dirs/electra_run_true_1-step_38000-eval-testing.json\n"
     ]
    }
   ],
   "source": [
    "# Get model to use\n",
    "target_seed = 3\n",
    "# model_type = 'glove'\n",
    "# model_type = 'bert'\n",
    "# model_type = 'electra'\n",
    "model_type = 't5'\n",
    "\n",
    "infer_paths, debug_paths, eval_paths = get_info_paths(model_type, target_seed)\n",
    "if model_type == 'bert':\n",
    "    trained_models = trained_bert_models\n",
    "    model_idx = model_seeds.index(target_seed)\n",
    "elif model_type == 'electra':\n",
    "    trained_models = trained_electra_models\n",
    "    model_idx = model_seeds.index(target_seed)\n",
    "elif model_type == 't5':\n",
    "    trained_models = trained_t5_models\n",
    "    assert target_seed == 3\n",
    "    model_idx = 0\n",
    "elif model_type == 'glove':\n",
    "    trained_models = trained_glove_models\n",
    "    model_idx = [0,1,2].index(target_seed)\n",
    "target_model, last_step = trained_models[model_idx]\n",
    "\n",
    "# Do inference on custom query\n",
    "db_id = 'concert_singer'\n",
    "question = \"What is the average and maximum capacities for all stadiums ?\"\n",
    "gold = \"select avg(capacity) , max(capacity) from stadium\"\n",
    "model_type=model_type\n",
    "cem = [] # Column exact match\n",
    "tem = [] # Table exact match\n",
    "cpm = [] # Column partial match\n",
    "tpm = [] # table partial match\n",
    "cm = [] # cell match\n",
    "nm = [] # number match\n",
    "dm = [] # date match\n",
    "cem_exclude=[]\n",
    "tem_exclude=[]\n",
    "cpm_exclude=[]\n",
    "test_info = TestInfo(question, gold, db_id, target_seed, model_type, cem, tem, cpm, tpm, cm, nm, dm, \n",
    "                                                         cem_exclude, tem_exclude, cpm_exclude)\n",
    "test_example(target_model, test_info, step=last_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ca6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis options\n",
    "analysis_type = ['attention_flow', 'relation_embeddings']\n",
    "              #   ['sim_logits', 'attn_probs', 'emb_sim_logits', 'bias_sim_logits',\n",
    "              # 'relation_k_embs', 'relation_v_embs',\n",
    "              # 'm2c_align_mat', 'm2t_align_mat']\n",
    "\n",
    "if model_type == 'glove':\n",
    "    model_idx = [0,1,2].index(target_seed)\n",
    "elif model_type == 't5':\n",
    "    assert target_seed == 3\n",
    "    model_idx = 0\n",
    "else:\n",
    "    model_idx = model_seeds.index(target_seed)\n",
    "# inspect_step_idx = 0\n",
    "inspect_layer_num = None\n",
    "# inspect_layer_num = 0\n",
    "# src_idx = 3\n",
    "# des_idx = 6\n",
    "# src_idx = 6\n",
    "# des_idx = 3\n",
    "# src_idx = 3\n",
    "# des_idx = 18\n",
    "src_idx = 0\n",
    "des_idx = 1\n",
    "# des_idx = None\n",
    "# target_key = 'attention_flow'\n",
    "# target_key = 'attention_score'\n",
    "# target_key = 'relation_embeddings'\n",
    "target_key = 'print_relation_embeddings'\n",
    "# target_key = 'draw_relation_embeddings'\n",
    "# target_key = 'draw_word_embeddings'\n",
    "# target_key = 'draw_attention_prob'\n",
    "eval_result, debug_result, debug_cache, infer_result = get_info(eval_paths[model_idx],\n",
    "                                                                     debug_paths[model_idx],\n",
    "                                                                     infer_paths[model_idx],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5303bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GET COLUMN AND TABLE INDEX\n",
    "# show_schema_entity_indices(eval_result, debug_result, debug_cache, infer_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a9b776",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is_correct:False\n",
      "DB_id:concert_singer\n",
      "NL:['what', 'is', 'the', 'average', 'and', 'maximum', 'capacities', 'for', 'all', 'stadiums', '?']\n",
      "Pred:SELECT Avg(stadium.Capacity), Max(stadium.Highest) FROM stadium\n",
      "Gold:select avg(capacity) , max(capacity) from stadium\n",
      "\n",
      "\n",
      "layer_num:1\n",
      "id: 0 relation: qq_dist_-2 bias: -0.9006960391998291\n",
      "id: 1 relation: qq_dist_-1 bias: 0.1648692488670349\n",
      "id: 2 relation: qq_dist_0 bias: 0.5849505066871643\n",
      "id: 3 relation: qq_dist_1 bias: 0.4960748851299286\n",
      "id: 4 relation: qq_dist_2 bias: -0.9137200713157654\n",
      "id: 5 relation: qc_default bias: 0.6164953708648682\n",
      "id: 6 relation: qt_default bias: 0.5735823512077332\n",
      "id: 7 relation: cq_default bias: -2.023505210876465\n",
      "id: 8 relation: cc_default bias: -1.0111944675445557\n",
      "id: 9 relation: cc_foreign_key_forward bias: 0.292309045791626\n",
      "id: 10 relation: cc_foreign_key_backward bias: -0.31689342856407166\n",
      "id: 11 relation: cc_table_match bias: -0.37508654594421387\n",
      "id: 14 relation: cc_dist_0 bias: 1.07600736618042\n",
      "id: 19 relation: ct_primary_key bias: 1.3615052700042725\n",
      "id: 20 relation: ct_table_match bias: 0.5618854761123657\n",
      "id: 21 relation: ct_any_table bias: 0.828244149684906\n",
      "id: 22 relation: tq_default bias: -1.7555898427963257\n",
      "id: 24 relation: tc_primary_key bias: 0.6850900053977966\n",
      "id: 25 relation: tc_table_match bias: 0.013357792049646378\n",
      "id: 26 relation: tc_any_table bias: 0.010601066052913666\n",
      "id: 28 relation: tt_default bias: 0.13892590999603271\n",
      "id: 29 relation: tt_foreign_key_forward bias: 0.38435885310173035\n",
      "id: 30 relation: tt_foreign_key_backward bias: -0.12505494058132172\n",
      "id: 34 relation: tt_dist_0 bias: 1.3147999048233032\n",
      "id: 37 relation: qcCEM bias: 1.197742223739624\n",
      "id: 38 relation: cqCEM bias: 0.8924532532691956\n",
      "id: 39 relation: qtTEM bias: 0.6722587943077087\n",
      "id: 40 relation: tqTEM bias: 0.9176223874092102\n",
      "id: 41 relation: qcCPM bias: 1.1626187562942505\n",
      "id: 42 relation: cqCPM bias: 0.9870843887329102\n",
      "id: 43 relation: qtTPM bias: 0.6589078307151794\n",
      "id: 44 relation: tqTPM bias: -0.5456562042236328\n",
      "id: 45 relation: qcNUMBER bias: 1.0910249948501587\n",
      "id: 46 relation: cqNUMBER bias: -0.5648890137672424\n",
      "id: 47 relation: qcTIME bias: -0.4553249776363373\n",
      "id: 48 relation: cqTIME bias: 0.14262470602989197\n",
      "id: 49 relation: qcCELLMATCH bias: 1.649129867553711\n",
      "id: 50 relation: cqCELLMATCH bias: -0.17480440437793732\n",
      "\n",
      "layer_num:2\n",
      "id: 0 relation: qq_dist_-2 bias: -0.48108088970184326\n",
      "id: 1 relation: qq_dist_-1 bias: 0.6805501580238342\n",
      "id: 2 relation: qq_dist_0 bias: -2.249422788619995\n",
      "id: 3 relation: qq_dist_1 bias: 1.4723492860794067\n",
      "id: 4 relation: qq_dist_2 bias: 0.10187724232673645\n",
      "id: 5 relation: qc_default bias: 0.16116224229335785\n",
      "id: 6 relation: qt_default bias: -0.46069103479385376\n",
      "id: 7 relation: cq_default bias: -0.22602157294750214\n",
      "id: 8 relation: cc_default bias: -0.36314794421195984\n",
      "id: 9 relation: cc_foreign_key_forward bias: -1.3945136070251465\n",
      "id: 10 relation: cc_foreign_key_backward bias: 0.8486855626106262\n",
      "id: 11 relation: cc_table_match bias: 0.5669549107551575\n",
      "id: 14 relation: cc_dist_0 bias: -0.39086994528770447\n",
      "id: 19 relation: ct_primary_key bias: 0.7131209373474121\n",
      "id: 20 relation: ct_table_match bias: 0.7342303395271301\n",
      "id: 21 relation: ct_any_table bias: 1.5489917993545532\n",
      "id: 22 relation: tq_default bias: 1.0782396793365479\n",
      "id: 24 relation: tc_primary_key bias: 0.9470542073249817\n",
      "id: 25 relation: tc_table_match bias: -1.2570269107818604\n",
      "id: 26 relation: tc_any_table bias: 1.1537823677062988\n",
      "id: 28 relation: tt_default bias: -1.3813015222549438\n",
      "id: 29 relation: tt_foreign_key_forward bias: 0.012873739004135132\n",
      "id: 30 relation: tt_foreign_key_backward bias: -1.0524539947509766\n",
      "id: 34 relation: tt_dist_0 bias: 1.449501872062683\n",
      "id: 37 relation: qcCEM bias: -0.2524797022342682\n",
      "id: 38 relation: cqCEM bias: 2.1848790645599365\n",
      "id: 39 relation: qtTEM bias: -1.168596625328064\n",
      "id: 40 relation: tqTEM bias: 0.4416084587574005\n",
      "id: 41 relation: qcCPM bias: -0.6947211623191833\n",
      "id: 42 relation: cqCPM bias: 0.7114366888999939\n",
      "id: 43 relation: qtTPM bias: 0.9847816228866577\n",
      "id: 44 relation: tqTPM bias: 0.6710576415061951\n",
      "id: 45 relation: qcNUMBER bias: -0.29110682010650635\n",
      "id: 46 relation: cqNUMBER bias: 0.0018691818695515394\n",
      "id: 47 relation: qcTIME bias: -0.22919462621212006\n",
      "id: 48 relation: cqTIME bias: 0.3005428910255432\n",
      "id: 49 relation: qcCELLMATCH bias: -0.11647840589284897\n",
      "id: 50 relation: cqCELLMATCH bias: 0.12420966476202011\n",
      "\n",
      "layer_num:3\n",
      "id: 0 relation: qq_dist_-2 bias: 1.8242837190628052\n",
      "id: 1 relation: qq_dist_-1 bias: 0.24272029101848602\n",
      "id: 2 relation: qq_dist_0 bias: -0.37206077575683594\n",
      "id: 3 relation: qq_dist_1 bias: -0.8960325717926025\n",
      "id: 4 relation: qq_dist_2 bias: 0.2573195695877075\n",
      "id: 5 relation: qc_default bias: -1.5273000001907349\n",
      "id: 6 relation: qt_default bias: -1.3757644891738892\n",
      "id: 7 relation: cq_default bias: -1.2989929914474487\n",
      "id: 8 relation: cc_default bias: 0.25154468417167664\n",
      "id: 9 relation: cc_foreign_key_forward bias: 0.32245585322380066\n",
      "id: 10 relation: cc_foreign_key_backward bias: 1.4556845426559448\n",
      "id: 11 relation: cc_table_match bias: -0.6318883299827576\n",
      "id: 14 relation: cc_dist_0 bias: -2.451524496078491\n",
      "id: 19 relation: ct_primary_key bias: -0.22290171682834625\n",
      "id: 20 relation: ct_table_match bias: 1.093477725982666\n",
      "id: 21 relation: ct_any_table bias: -0.7808294296264648\n",
      "id: 22 relation: tq_default bias: 0.7741594314575195\n",
      "id: 24 relation: tc_primary_key bias: -1.3427642583847046\n",
      "id: 25 relation: tc_table_match bias: 0.5950411558151245\n",
      "id: 26 relation: tc_any_table bias: 0.23157824575901031\n",
      "id: 28 relation: tt_default bias: 0.6024932861328125\n",
      "id: 29 relation: tt_foreign_key_forward bias: -1.6949328184127808\n",
      "id: 30 relation: tt_foreign_key_backward bias: 2.378765344619751\n",
      "id: 34 relation: tt_dist_0 bias: 0.9757854342460632\n",
      "id: 37 relation: qcCEM bias: 0.5240100622177124\n",
      "id: 38 relation: cqCEM bias: 0.39033493399620056\n",
      "id: 39 relation: qtTEM bias: -0.1513083130121231\n",
      "id: 40 relation: tqTEM bias: -1.2213819026947021\n",
      "id: 41 relation: qcCPM bias: 2.4783167839050293\n",
      "id: 42 relation: cqCPM bias: 1.2543118000030518\n",
      "id: 43 relation: qtTPM bias: -0.5626456141471863\n",
      "id: 44 relation: tqTPM bias: 0.8678396344184875\n",
      "id: 45 relation: qcNUMBER bias: -0.4668295681476593\n",
      "id: 46 relation: cqNUMBER bias: -0.24774640798568726\n",
      "id: 47 relation: qcTIME bias: 0.35163095593452454\n",
      "id: 48 relation: cqTIME bias: -0.7950264811515808\n",
      "id: 49 relation: qcCELLMATCH bias: 0.1836806684732437\n",
      "id: 50 relation: cqCELLMATCH bias: 0.8645668029785156\n",
      "\n",
      "layer_num:4\n",
      "id: 0 relation: qq_dist_-2 bias: -0.5063520669937134\n",
      "id: 1 relation: qq_dist_-1 bias: 0.5059336423873901\n",
      "id: 2 relation: qq_dist_0 bias: -0.40981194376945496\n",
      "id: 3 relation: qq_dist_1 bias: 0.20258161425590515\n",
      "id: 4 relation: qq_dist_2 bias: -0.8531244993209839\n",
      "id: 5 relation: qc_default bias: -0.9602171182632446\n",
      "id: 6 relation: qt_default bias: -1.0430002212524414\n",
      "id: 7 relation: cq_default bias: -2.043030023574829\n",
      "id: 8 relation: cc_default bias: 0.45473119616508484\n",
      "id: 9 relation: cc_foreign_key_forward bias: -0.13189026713371277\n",
      "id: 10 relation: cc_foreign_key_backward bias: 0.14457030594348907\n",
      "id: 11 relation: cc_table_match bias: 1.6973236799240112\n",
      "id: 14 relation: cc_dist_0 bias: -0.3550110459327698\n",
      "id: 19 relation: ct_primary_key bias: -0.4160287082195282\n",
      "id: 20 relation: ct_table_match bias: -1.0344886779785156\n",
      "id: 21 relation: ct_any_table bias: 0.06268396228551865\n",
      "id: 22 relation: tq_default bias: -2.1264944076538086\n",
      "id: 24 relation: tc_primary_key bias: -1.008950114250183\n",
      "id: 25 relation: tc_table_match bias: 0.28880834579467773\n",
      "id: 26 relation: tc_any_table bias: -0.0131516819819808\n",
      "id: 28 relation: tt_default bias: -1.0417609214782715\n",
      "id: 29 relation: tt_foreign_key_forward bias: -1.0698007345199585\n",
      "id: 30 relation: tt_foreign_key_backward bias: 0.8404867053031921\n",
      "id: 34 relation: tt_dist_0 bias: -0.675655722618103\n",
      "id: 37 relation: qcCEM bias: 0.7981560826301575\n",
      "id: 38 relation: cqCEM bias: 1.4140276908874512\n",
      "id: 39 relation: qtTEM bias: 0.6661211848258972\n",
      "id: 40 relation: tqTEM bias: 2.134007453918457\n",
      "id: 41 relation: qcCPM bias: 1.0869392156600952\n",
      "id: 42 relation: cqCPM bias: 1.0849071741104126\n",
      "id: 43 relation: qtTPM bias: -0.3522586226463318\n",
      "id: 44 relation: tqTPM bias: -1.7443571090698242\n",
      "id: 45 relation: qcNUMBER bias: 1.1525558233261108\n",
      "id: 46 relation: cqNUMBER bias: 1.6667373180389404\n",
      "id: 47 relation: qcTIME bias: -1.0614991188049316\n",
      "id: 48 relation: cqTIME bias: 0.6033947467803955\n",
      "id: 49 relation: qcCELLMATCH bias: -0.11217282712459564\n",
      "id: 50 relation: cqCELLMATCH bias: 1.634678840637207\n",
      "\n",
      "layer_num:5\n",
      "id: 0 relation: qq_dist_-2 bias: 0.24429023265838623\n",
      "id: 1 relation: qq_dist_-1 bias: -0.32412099838256836\n",
      "id: 2 relation: qq_dist_0 bias: 1.6916980743408203\n",
      "id: 3 relation: qq_dist_1 bias: 0.9663048386573792\n",
      "id: 4 relation: qq_dist_2 bias: 1.355079174041748\n",
      "id: 5 relation: qc_default bias: 1.2467695474624634\n",
      "id: 6 relation: qt_default bias: 0.26815927028656006\n",
      "id: 7 relation: cq_default bias: -0.2937331199645996\n",
      "id: 8 relation: cc_default bias: -1.6753315925598145\n",
      "id: 9 relation: cc_foreign_key_forward bias: 2.005993604660034\n",
      "id: 10 relation: cc_foreign_key_backward bias: 1.1720277070999146\n",
      "id: 11 relation: cc_table_match bias: 0.41543227434158325\n",
      "id: 14 relation: cc_dist_0 bias: 0.34624770283699036\n",
      "id: 19 relation: ct_primary_key bias: -0.7037533521652222\n",
      "id: 20 relation: ct_table_match bias: 1.622641921043396\n",
      "id: 21 relation: ct_any_table bias: 1.1356756687164307\n",
      "id: 22 relation: tq_default bias: -0.3860493004322052\n",
      "id: 24 relation: tc_primary_key bias: -1.7803881168365479\n",
      "id: 25 relation: tc_table_match bias: 0.03316734358668327\n",
      "id: 26 relation: tc_any_table bias: 0.3458614945411682\n",
      "id: 28 relation: tt_default bias: -0.24290139973163605\n",
      "id: 29 relation: tt_foreign_key_forward bias: 1.2177999019622803\n",
      "id: 30 relation: tt_foreign_key_backward bias: 1.7003644704818726\n",
      "id: 34 relation: tt_dist_0 bias: -0.3142317235469818\n",
      "id: 37 relation: qcCEM bias: -1.3058974742889404\n",
      "id: 38 relation: cqCEM bias: 1.8176816701889038\n",
      "id: 39 relation: qtTEM bias: 0.8551611304283142\n",
      "id: 40 relation: tqTEM bias: -1.7131961584091187\n",
      "id: 41 relation: qcCPM bias: 1.5345723628997803\n",
      "id: 42 relation: cqCPM bias: -0.8938184976577759\n",
      "id: 43 relation: qtTPM bias: -0.3104311227798462\n",
      "id: 44 relation: tqTPM bias: -0.7506417036056519\n",
      "id: 45 relation: qcNUMBER bias: 0.44000735878944397\n",
      "id: 46 relation: cqNUMBER bias: -0.34270188212394714\n",
      "id: 47 relation: qcTIME bias: 0.7932041883468628\n",
      "id: 48 relation: cqTIME bias: -1.3214294910430908\n",
      "id: 49 relation: qcCELLMATCH bias: -0.25078970193862915\n",
      "id: 50 relation: cqCELLMATCH bias: -0.3843652904033661\n",
      "\n",
      "layer_num:6\n",
      "id: 0 relation: qq_dist_-2 bias: 0.19623565673828125\n",
      "id: 1 relation: qq_dist_-1 bias: 0.8930761218070984\n",
      "id: 2 relation: qq_dist_0 bias: -2.303070545196533\n",
      "id: 3 relation: qq_dist_1 bias: -0.7589355111122131\n",
      "id: 4 relation: qq_dist_2 bias: 1.4676854610443115\n",
      "id: 5 relation: qc_default bias: -0.3696417510509491\n",
      "id: 6 relation: qt_default bias: 0.45164769887924194\n",
      "id: 7 relation: cq_default bias: -1.3604018688201904\n",
      "id: 8 relation: cc_default bias: -0.8725472092628479\n",
      "id: 9 relation: cc_foreign_key_forward bias: 1.0453176498413086\n",
      "id: 10 relation: cc_foreign_key_backward bias: 0.13877950608730316\n",
      "id: 11 relation: cc_table_match bias: -0.03883281722664833\n",
      "id: 14 relation: cc_dist_0 bias: -1.969042420387268\n",
      "id: 19 relation: ct_primary_key bias: 0.518795371055603\n",
      "id: 20 relation: ct_table_match bias: 0.8991777300834656\n",
      "id: 21 relation: ct_any_table bias: 0.7975781559944153\n",
      "id: 22 relation: tq_default bias: -0.07877334952354431\n",
      "id: 24 relation: tc_primary_key bias: -0.11113711446523666\n",
      "id: 25 relation: tc_table_match bias: -0.48808377981185913\n",
      "id: 26 relation: tc_any_table bias: -1.8060896396636963\n",
      "id: 28 relation: tt_default bias: -0.6774535775184631\n",
      "id: 29 relation: tt_foreign_key_forward bias: -1.8086662292480469\n",
      "id: 30 relation: tt_foreign_key_backward bias: 0.5822521448135376\n",
      "id: 34 relation: tt_dist_0 bias: -1.4608055353164673\n",
      "id: 37 relation: qcCEM bias: 0.16524577140808105\n",
      "id: 38 relation: cqCEM bias: 1.6647566556930542\n",
      "id: 39 relation: qtTEM bias: -0.21349023282527924\n",
      "id: 40 relation: tqTEM bias: 1.134959101676941\n",
      "id: 41 relation: qcCPM bias: 0.13346564769744873\n",
      "id: 42 relation: cqCPM bias: 2.79518461227417\n",
      "id: 43 relation: qtTPM bias: -0.01067796815186739\n",
      "id: 44 relation: tqTPM bias: 0.758978545665741\n",
      "id: 45 relation: qcNUMBER bias: -0.40266153216362\n",
      "id: 46 relation: cqNUMBER bias: -0.3684971332550049\n",
      "id: 47 relation: qcTIME bias: -0.4623847007751465\n",
      "id: 48 relation: cqTIME bias: 1.4229776859283447\n",
      "id: 49 relation: qcCELLMATCH bias: 0.8453996181488037\n",
      "id: 50 relation: cqCELLMATCH bias: -0.17817801237106323\n",
      "\n",
      "layer_num:7\n",
      "id: 0 relation: qq_dist_-2 bias: 0.1058044508099556\n",
      "id: 1 relation: qq_dist_-1 bias: 1.1676594018936157\n",
      "id: 2 relation: qq_dist_0 bias: -1.1587382555007935\n",
      "id: 3 relation: qq_dist_1 bias: 0.006650978233665228\n",
      "id: 4 relation: qq_dist_2 bias: -1.9287067651748657\n",
      "id: 5 relation: qc_default bias: -0.016640588641166687\n",
      "id: 6 relation: qt_default bias: -0.7183309197425842\n",
      "id: 7 relation: cq_default bias: 0.13394252955913544\n",
      "id: 8 relation: cc_default bias: -0.7441815137863159\n",
      "id: 9 relation: cc_foreign_key_forward bias: 0.407116174697876\n",
      "id: 10 relation: cc_foreign_key_backward bias: 1.2413320541381836\n",
      "id: 11 relation: cc_table_match bias: -0.04176165908575058\n",
      "id: 14 relation: cc_dist_0 bias: -1.8321936130523682\n",
      "id: 19 relation: ct_primary_key bias: -0.7958850860595703\n",
      "id: 20 relation: ct_table_match bias: -1.2653286457061768\n",
      "id: 21 relation: ct_any_table bias: -0.22781293094158173\n",
      "id: 22 relation: tq_default bias: -0.39476385712623596\n",
      "id: 24 relation: tc_primary_key bias: -0.5185831785202026\n",
      "id: 25 relation: tc_table_match bias: 1.3258074522018433\n",
      "id: 26 relation: tc_any_table bias: -0.8356622457504272\n",
      "id: 28 relation: tt_default bias: -1.3858723640441895\n",
      "id: 29 relation: tt_foreign_key_forward bias: 0.4527799189090729\n",
      "id: 30 relation: tt_foreign_key_backward bias: -0.27229684591293335\n",
      "id: 34 relation: tt_dist_0 bias: -0.6091725826263428\n",
      "id: 37 relation: qcCEM bias: 1.5729951858520508\n",
      "id: 38 relation: cqCEM bias: 0.23763923346996307\n",
      "id: 39 relation: qtTEM bias: 0.41446948051452637\n",
      "id: 40 relation: tqTEM bias: 1.1610103845596313\n",
      "id: 41 relation: qcCPM bias: 0.35821661353111267\n",
      "id: 42 relation: cqCPM bias: -1.3169457912445068\n",
      "id: 43 relation: qtTPM bias: 0.75018310546875\n",
      "id: 44 relation: tqTPM bias: 0.1462218314409256\n",
      "id: 45 relation: qcNUMBER bias: 0.02494846284389496\n",
      "id: 46 relation: cqNUMBER bias: -0.7593543529510498\n",
      "id: 47 relation: qcTIME bias: -0.5161616206169128\n",
      "id: 48 relation: cqTIME bias: -1.2845319509506226\n",
      "id: 49 relation: qcCELLMATCH bias: -0.22902686893939972\n",
      "id: 50 relation: cqCELLMATCH bias: -1.6605911254882812\n",
      "\n",
      "layer_num:8\n",
      "id: 0 relation: qq_dist_-2 bias: 1.3516985177993774\n",
      "id: 1 relation: qq_dist_-1 bias: -0.9047179222106934\n",
      "id: 2 relation: qq_dist_0 bias: 1.5550988912582397\n",
      "id: 3 relation: qq_dist_1 bias: -1.7909879684448242\n",
      "id: 4 relation: qq_dist_2 bias: -1.9709728956222534\n",
      "id: 5 relation: qc_default bias: 1.034471035003662\n",
      "id: 6 relation: qt_default bias: -2.2316176891326904\n",
      "id: 7 relation: cq_default bias: 0.15014396607875824\n",
      "id: 8 relation: cc_default bias: 1.906775712966919\n",
      "id: 9 relation: cc_foreign_key_forward bias: 1.8010226488113403\n",
      "id: 10 relation: cc_foreign_key_backward bias: 1.366745114326477\n",
      "id: 11 relation: cc_table_match bias: 1.0439300537109375\n",
      "id: 14 relation: cc_dist_0 bias: -0.7943220734596252\n",
      "id: 19 relation: ct_primary_key bias: -0.5334613919258118\n",
      "id: 20 relation: ct_table_match bias: -0.13862760365009308\n",
      "id: 21 relation: ct_any_table bias: 0.755669116973877\n",
      "id: 22 relation: tq_default bias: -1.664346694946289\n",
      "id: 24 relation: tc_primary_key bias: 1.953643560409546\n",
      "id: 25 relation: tc_table_match bias: 1.4463834762573242\n",
      "id: 26 relation: tc_any_table bias: -1.0050873756408691\n",
      "id: 28 relation: tt_default bias: 0.004859840031713247\n",
      "id: 29 relation: tt_foreign_key_forward bias: -0.6874573826789856\n",
      "id: 30 relation: tt_foreign_key_backward bias: 0.8809383511543274\n",
      "id: 34 relation: tt_dist_0 bias: -1.363936185836792\n",
      "id: 37 relation: qcCEM bias: 0.030784646049141884\n",
      "id: 38 relation: cqCEM bias: -0.4878788888454437\n",
      "id: 39 relation: qtTEM bias: -0.8819335699081421\n",
      "id: 40 relation: tqTEM bias: 1.0984352827072144\n",
      "id: 41 relation: qcCPM bias: 0.4299617111682892\n",
      "id: 42 relation: cqCPM bias: -0.3124656677246094\n",
      "id: 43 relation: qtTPM bias: -0.2766305208206177\n",
      "id: 44 relation: tqTPM bias: 2.110644578933716\n",
      "id: 45 relation: qcNUMBER bias: -0.028082959353923798\n",
      "id: 46 relation: cqNUMBER bias: -0.017612814903259277\n",
      "id: 47 relation: qcTIME bias: 0.5080773234367371\n",
      "id: 48 relation: cqTIME bias: -0.7190797328948975\n",
      "id: 49 relation: qcCELLMATCH bias: -0.8344683051109314\n",
      "id: 50 relation: cqCELLMATCH bias: 1.9195919036865234\n"
     ]
    }
   ],
   "source": [
    "# Do analysis\n",
    "show_encoder_details(eval_result, debug_result, debug_cache, infer_result, src_idx, des_idx, inspect_layer_num, target_key, top_k=None, prefix=f'seed_{target_seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b7592ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_basic_details(eval_result, debug_result, debug_cache, infer_result)\n",
    "# db_id = eval_result['db_id']\n",
    "# pred = eval_result['predicted']\n",
    "# gold = eval_result['gold']\n",
    "# decode_history = debug_result['history']\n",
    "# correct = eval_result['exact']\n",
    "# questions = debug_cache['question']\n",
    "# input_columns = debug_cache['columns']\n",
    "# input_tables = debug_cache['tables']\n",
    "# columns = get_column_names(db_id)\n",
    "# tables = get_table_names(db_id)\n",
    "# assert len(columns) == len(input_columns), f\"{len(columns)} vs {len(input_columns)}\"\n",
    "# assert len(tables) == len(input_tables), f\"{len(tables)} vs {len(input_tables)}\"\n",
    "# tokens = questions + columns + tables\n",
    "# tokens_len = len(tokens)\n",
    "# bert_attention = torch.stack(debug_cache['bert_attention']).squeeze(1)\n",
    "# bert_attention = bert_attention[:2]\n",
    "# bert_tokens = debug_cache['input_tokens']\n",
    "# flow_att_mat = get_attention_flow(bert_tokens, bert_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = ' '.join(bert_tokens[1:-1])\n",
    "# draw_attention_flow(sentence, 3, flow_att_mat, [10, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e730bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decoder_inspect_step_idx = None\n",
    "# show_decoder_details(eval_result, debug_result, debug_cache, infer_result, inspect_step_idx=decoder_inspect_step_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc8754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8fac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c71c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87bb932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04081c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16018f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26a5743f5e35ae6571ca824f6fe42c87a3d3bd35a3dc9ed4a68e9bd849c38ffd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
